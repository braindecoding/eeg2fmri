# ğŸ§  CortexFlow EEG Adapter

**A Novel Neural Transformer Vision Transformer (NT-ViT) Adapter** - Enabling EEG signal integration with CortexFlow framework for brain-to-image reconstruction. This adapter converts EEG signals to synthetic fMRI data compatible with existing CortexFlow pipelines.

[![Python 3.11](https://img.shields.io/badge/python-3.11.12-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.7.1+cu128-red.svg)](https://pytorch.org/)
[![CUDA](https://img.shields.io/badge/CUDA-12.8-green.svg)](https://developer.nvidia.com/cuda-downloads)
[![NumPy](https://img.shields.io/badge/NumPy-2.1.3-lightblue.svg)](https://numpy.org/)
[![SciPy](https://img.shields.io/badge/SciPy-1.15.3-yellow.svg)](https://scipy.org/)
[![Research](https://img.shields.io/badge/Research-Dissertation-orange.svg)](https://github.com)

## ğŸ¯ **Overview**

**CortexFlow EEG Adapter** introduces a novel approach to integrate EEG signals with the CortexFlow framework through a custom **Neural Transformer Vision Transformer (NT-ViT)** architecture. This adapter enables researchers to leverage EEG data for brain-to-image reconstruction tasks previously limited to fMRI inputs.

### **Key Innovation**
This work presents the **first EEG adapter for CortexFlow**, bridging the gap between non-invasive EEG recordings and advanced brain-to-image reconstruction capabilities.

### **Research Contributions**
- ğŸ”¬ **Novel EEG Integration**: First adapter enabling EEG input for CortexFlow
- ğŸ§  **NT-ViT Architecture**: Custom Vision Transformer for EEGâ†’fMRI synthesis
- ğŸ“Š **Multi-Dataset Training**: Unified approach for MindBigData + Crell datasets
- ğŸ”„ **Cross-Modal Alignment**: Advanced domain matching for neural signal translation
- âš¡ **Production Ready**: Robust implementation with comprehensive validation

### **Academic Impact**
- **Methodological Innovation**: Extends CortexFlow capabilities to EEG modality
- **Accessibility Enhancement**: Enables brain-to-image research with non-invasive EEG
- **Reproducible Research**: Complete pipeline with standardized evaluation protocols

## ğŸ“ **Directory Structure**

```
cortexflow-eeg-adapter/
â”œâ”€â”€ train_ntvit.py                # NT-ViT training pipeline
â”œâ”€â”€ ntvit_to_cortexflow.py        # CortexFlow adapter converter
â”œâ”€â”€ verify_cortexflow.py          # Data validation script
â”œâ”€â”€ generate_full_samples.py      # Full dataset sample generator
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ RESEARCH_CONTRIBUTIONS.md     # Academic documentation
â”œâ”€â”€ datasets/                     # Input datasets
â”‚   â”œâ”€â”€ EP1.01.txt               # MindBigData EEG data
â”‚   â”œâ”€â”€ S01.mat                  # Crell EEG data
â”‚   â”œâ”€â”€ MindbigdataStimuli/      # Digit stimuli (0.jpg - 9.jpg)
â”‚   â””â”€â”€ crellStimuli/            # Letter stimuli (a.png, d.png, etc.)
â”œâ”€â”€ ntvit_outputs/               # NT-ViT generated outputs
â”‚   â”œâ”€â”€ ntvit_*_final.pth       # Trained model weights
â”‚   â”œâ”€â”€ *_synthetic_fmri_000-049.npy  # Full synthetic fMRI samples (100 total)
â”‚   â””â”€â”€ *_synthetic_fmri_000-049.json # Metadata for each sample
â”œâ”€â”€ cortexflow_data/            # CortexFlow-compatible outputs
â”‚   â”œâ”€â”€ mindbigdata.mat         # MindBigData for CortexFlow (50 samples)
â”‚   â””â”€â”€ crell.mat               # Crell for CortexFlow (50 samples)
â””â”€â”€ README.md                    # This file
```

## ğŸ”¬ **Supported Datasets**

### **MindBigData Dataset**
- **Format**: EP1.01.txt (tab-separated values)
- **Device**: EPOC (14 channels: AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4)
- **Sampling Rate**: ~128Hz
- **Duration**: 2 seconds per signal
- **Stimuli**: Digits 0-9 (visual presentation + thinking)
- **Processing**: 256 samples (2s Ã— 128Hz)

### **Crell Dataset**
- **Format**: S01.mat (MATLAB format)
- **Device**: 64 EEG channels at 500Hz
- **Paradigm**: Visual letter presentation (a,d,e,f,j,n,o,s,t,v)
- **Phases**: Fade-in (2s) â†’ Full visibility (0.5s) â†’ Fade-out (2s)
- **Processing**: 2250 samples (4.5s Ã— 500Hz) - **Visual phases only**
- **Motor Phase**: Excluded (focus on visual processing only)

## âš™ï¸ **NT-ViT Architecture**

```
EEG Signal â†’ Mel Spectrogram â†’ ViT Encoder â†’ ViT Decoder â†’ Synthetic fMRI
    â†“              â†“               â†“            â†“             â†“
[N, C, T]    [N, 3, H, W]    [N, embed_dim]  [N, queries]  [N, 15724]
```

### **Core Components**
1. **SpectrogramGenerator**: Converts EEG to mel spectrograms with channel fusion
2. **VisionTransformerEncoder**: Patches + positional encoding + transformer layers
3. **VisionTransformerDecoder**: Learnable queries + cross-attention + output projection
4. **DomainMatchingModule**: Contrastive learning for EEG-fMRI alignment

## ğŸš€ **Quick Start**

### **Prerequisites**

**System Requirements:**
- Python 3.11.12
- CUDA 12.8 compatible GPU
- WSL (Windows Subsystem for Linux) recommended

**Required Packages:**
```bash
# PyTorch with CUDA 12.8 support
pip install torch==2.7.1+cu128 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Scientific computing packages
pip install scipy==1.15.3 numpy==2.1.3

# Additional dependencies
pip install matplotlib pillow
```

**Alternative Installation (using requirements.txt):**
```bash
pip install -r requirements.txt
```

**Verify Installation:**
```bash
wsl python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
# Expected output: PyTorch: 2.7.1+cu128, CUDA: True
```

### **Step 1: Prepare Data**
Ensure your directory structure matches:
```
datasets/
â”œâ”€â”€ EP1.01.txt                    # MindBigData EEG file
â”œâ”€â”€ S01.mat                       # Crell EEG file
â”œâ”€â”€ MindbigdataStimuli/           # Digit images
â”‚   â”œâ”€â”€ 0.jpg
â”‚   â”œâ”€â”€ 1.jpg
â”‚   â””â”€â”€ ... (up to 9.jpg)
â””â”€â”€ crellStimuli/                 # Letter images
    â”œâ”€â”€ a.png
    â”œâ”€â”€ d.png
    â””â”€â”€ ... (e,f,j,n,o,s,t,v.png)
```

### **Step 2: Run Training**
```bash
# Always run in WSL for optimal performance
wsl python train_ntvit.py
```

**Expected Output:**
- Training progress for 20 epochs
- Model checkpoints saved at epochs 10, 20, and final
- Loss convergence (MindBigData: ~0.44, Crell: ~0.36)
- **100 synthetic fMRI samples generated** (50 per dataset, 000-049)

### **Step 3: Generate Additional Samples (Optional)**
```bash
# Generate more samples from trained models using real EEG data
wsl python generate_full_samples.py
```

**Output:**
- Uses trained NT-ViT models to generate synthetic fMRI from real EEG
- Creates 100 samples total (50 MindBigData + 50 Crell)
- Each sample includes .npy (fMRI data) + .json (metadata)

### **Step 4: Monitor Training**
```
ğŸ§  NT-ViT Training Pipeline
==================================================
Loading MindBigData from datasets/EP1.01.txt...
Loaded 50 MindBigData samples
Loading Crell data from datasets/S01.mat...
Found 320 visual letter events
Loaded 50 Crell samples

Epoch 1/20
  MindBigData loss: 0.5321
  Crell loss: 0.5334
...
Epoch 20/20
  MindBigData loss: 0.4367
  Crell loss: 0.3563
âœ… Training complete!
```

## ğŸ“Š **Generated Outputs**

### **Model Checkpoints**
```
ntvit_outputs/
â”œâ”€â”€ ntvit_mindbigdata_final.pth   # MindBigData model (14 channels)
â”œâ”€â”€ ntvit_crell_final.pth         # Crell model (64 channels)
â”œâ”€â”€ ntvit_*_epoch_*.pth          # Intermediate checkpoints
```

### **Synthetic fMRI Data**
```
â”œâ”€â”€ mindbigdata_synthetic_fmri_000.npy  # Shape: (15724,)
â”œâ”€â”€ mindbigdata_synthetic_fmri_001.npy  # Value range: [-0.996, +0.976]
â”œâ”€â”€ crell_synthetic_fmri_000.npy       # Shape: (15724,)
â”œâ”€â”€ crell_synthetic_fmri_001.npy       # Value range: [-0.951, +0.997]
```

### **Metadata Files**
```json
{
  "model": "NT-ViT",
  "dataset_type": "mindbigdata",
  "fmri_shape": [15724],
  "fmri_voxels": 15724,
  "value_range": [-0.996, 0.976],
  "compatible_with": "MindEye/NSD format"
}
```

## ğŸ”§ **Technical Specifications**

### **Model Architecture**
- **Embedding Dimension**: 256 (optimized for stability)
- **Attention Heads**: 8
- **Transformer Layers**: 6 (encoder) + 6 (decoder)
- **Patch Size**: 16Ã—16
- **Output Dimension**: 15,724 voxels (NSD format)

### **Training Configuration**
- **Learning Rate**: 1e-5 (with weight decay 1e-4)
- **Optimizer**: AdamW
- **Gradient Clipping**: max_norm=1.0
- **Batch Size**: 4
- **Epochs**: 20 (configurable)

### **Numerical Stability Features**
- âœ… Proper weight initialization (Xavier/Kaiming)
- âœ… Gradient clipping and NaN detection
- âœ… Input/output value clamping
- âœ… Batch normalization and dropout
- âœ… Robust data preprocessing

## ğŸ¯ **Integration with MindEye**

The generated synthetic fMRI files are directly compatible with MindEye:

```python
import numpy as np

# Load synthetic fMRI
synthetic_fmri = np.load('ntvit_outputs/mindbigdata_synthetic_fmri_000.npy')
print(f"Shape: {synthetic_fmri.shape}")  # (15724,)

# Use with MindEye for image reconstruction
# mindeye_model.predict(synthetic_fmri) â†’ reconstructed_image
```

## ğŸ“ˆ **Performance Metrics**

### **Training Convergence**
- **MindBigData**: Loss 0.532 â†’ 0.437 (stable convergence)
- **Crell**: Loss 0.533 â†’ 0.356 (excellent convergence)
- **No NaN Issues**: Robust numerical stability
- **Memory Efficient**: Optimized for GPU training

### **Data Processing**
- **MindBigData**: 50 samples (320 total events available)
- **Crell**: 50 samples (320 visual events detected)
- **Processing Speed**: ~1-2 minutes per epoch
- **Output Quality**: Consistent value ranges

## ï¿½ **CortexFlow Integration**

### **Step 5: Convert to CortexFlow Format**
```bash
# Generate CortexFlow-compatible MATLAB files
wsl python ntvit_to_cortexflow.py
```

**Output:**
- Creates `cortexflow_data/mindbigdata.mat` and `cortexflow_data/crell.mat`
- Each file contains 50 samples (40 train + 10 test)
- All stimuli represented in test set for comprehensive evaluation

### **Generated CortexFlow Datasets**

**MindBigData Dataset (mindbigdata.mat):**
```
ğŸ“ˆ fmriTrn: (40, 3092) - float64
    Range: [-0.924, 0.820], Mean: 0.039, Std: 0.342
ğŸ“ˆ stimTrn: (40, 784) - uint8 (28Ã—28 grayscale images)
ğŸ“ˆ fmriTest: (10, 3092) - float64
ğŸ“ˆ stimTest: (10, 784) - uint8
ğŸ“ˆ labelTrn: (40, 1) - uint8 (digits 0,1,2,3,4,5,6,7,8,9)
ğŸ“ˆ labelTest: (10, 1) - uint8 (digits 0,1,2,3,4,5,6,7,8,9)
```

**Crell Dataset (crell.mat):**
```
ğŸ“ˆ fmriTrn: (40, 3092) - float64
    Range: [-0.985, 0.999], Mean: 0.005, Std: 0.313
ğŸ“ˆ stimTrn: (40, 784) - uint8 (28Ã—28 grayscale images)
ğŸ“ˆ fmriTest: (10, 3092) - float64
ğŸ“ˆ stimTest: (10, 784) - uint8
ğŸ“ˆ labelTrn: (40, 1) - uint8 (letters a,d,e,f,j,n,o,s,t,v â†’ 1-10)
ğŸ“ˆ labelTest: (10, 1) - uint8 (letters a,d,e,f,j,n,o,s,t,v â†’ 1-10)
```

### **Usage with CortexFlow**
```python
import scipy.io

# Load MindBigData for CortexFlow
data_mb = scipy.io.loadmat('cortexflow_data/mindbigdata.mat')
fmri_train = data_mb['fmriTrn']    # (40, 3092)
stim_train = data_mb['stimTrn']    # (40, 784)
labels_train = data_mb['labelTrn'] # (40, 1)

# Load Crell for CortexFlow
data_crell = scipy.io.loadmat('cortexflow_data/crell.mat')
fmri_train_crell = data_crell['fmriTrn']    # (40, 3092)
stim_train_crell = data_crell['stimTrn']    # (40, 784)
labels_train_crell = data_crell['labelTrn'] # (40, 1)
```

### **CortexFlow Conversion Features**
- âœ… **Exact Format Match**: Compatible with CortexFlow requirements
- âœ… **Proper Data Types**: float64 (fMRI), uint8 (stimuli/labels)
- âœ… **Standard Dimensions**: 3092 fMRI voxels, 784 stimulus pixels
- âœ… **Balanced Split**: All stimuli represented in test set (comprehensive evaluation)
- âœ… **Multi-Modal**: fMRI + Visual stimuli + Class labels

### **Train/Test Split Strategy**
**Balanced Representation Approach:**
- **Test Set**: Contains 1 sample from EVERY stimulus class
- **Train Set**: Contains remaining samples from all classes

**MindBigData (Digits 0-9):**
- **Train**: 40 samples (4 samples per digit on average)
- **Test**: 10 samples (1 sample per digit: 0,1,2,3,4,5,6,7,8,9)

**Crell (Letters a,d,e,f,j,n,o,s,t,v):**
- **Train**: 40 samples (4 samples per letter on average)
- **Test**: 10 samples (1 sample per letter: a,d,e,f,j,n,o,s,t,v)

This ensures **complete stimulus coverage** in test set for comprehensive evaluation of all classes.

## ğŸ“Š **Generated Outputs**

### **NT-ViT Outputs (ntvit_outputs/)**
After training, you'll have:
- **6 Model Files**: `ntvit_*_final.pth` (trained models)
- **200 Sample Files**: 100 .npy + 100 .json files
  - `mindbigdata_synthetic_fmri_000-049.npy` (50 samples)
  - `crell_synthetic_fmri_000-049.npy` (50 samples)
  - Corresponding .json metadata files

### **CortexFlow Outputs (cortexflow_data/)**
Ready-to-use MATLAB files:
- **mindbigdata.mat**: 50 samples (40 train + 10 test)
- **crell.mat**: 50 samples (40 train + 10 test)

## ğŸš€ **Quick Start Workflow**

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Train NT-ViT models (generates 100 synthetic fMRI samples)
wsl python train_ntvit.py

# 3. Generate additional samples (optional)
wsl python generate_full_samples.py

# 4. Convert to CortexFlow format
wsl python ntvit_to_cortexflow.py

# 5. Verify results
wsl python verify_cortexflow.py
```

## ï¿½ğŸ”¬ **Research Applications & Impact**

### **Primary Research Domains**
- **ğŸ§  Computational Neuroscience**: Novel EEGâ†’fMRI synthesis methodology
- **ğŸ”¬ Brain-Computer Interfaces**: Non-invasive neural signal decoding
- **ğŸ¥ Medical Imaging**: Cost-effective alternative to fMRI acquisition
- **ğŸ¤– AI/ML Research**: Cross-modal neural architecture development

### **Dissertation Contributions**
- **ğŸ“š Methodological Innovation**: First EEG adapter for CortexFlow framework
- **ğŸ”§ Technical Advancement**: NT-ViT architecture for neural signal translation
- **ğŸ“Š Empirical Validation**: Comprehensive evaluation on multiple EEG datasets
- **ğŸŒ Open Science**: Reproducible research with complete implementation

### **Performance Metrics**
- **Training Convergence**: MindBigData (0.53â†’0.44), Crell (0.53â†’0.36)
- **Sample Generation**: 100 synthetic fMRI samples from real EEG data
- **Format Compatibility**: 100% CortexFlow format compliance
- **Data Quality**: Realistic fMRI activation ranges (-1 to +1)

### **Future Research Directions**
- **Real-time Processing**: Online EEGâ†’fMRI synthesis for live applications
- **Multi-modal Fusion**: Integration with other neuroimaging modalities
- **Clinical Applications**: Diagnostic and therapeutic applications

## ğŸ› ï¸ **Troubleshooting**

### **Common Issues**

**CUDA Out of Memory:**
```bash
# Reduce batch size in training
# Edit train_ntvit.py: batch_size=2 instead of 4
```

**Missing Dataset Files:**
```bash
# Ensure datasets/ folder contains:
# - EP1.01.txt (MindBigData)
# - S01.mat (Crell)
# - MindbigdataStimuli/ folder
# - crellStimuli/ folder
```

**Import Errors:**
```bash
# Verify all dependencies installed
pip install -r requirements.txt
wsl python -c "import torch, scipy, numpy; print('All imports OK')"
```

### **Performance Tips**
- **Use WSL**: Better performance than native Windows
- **CUDA Memory**: Monitor GPU memory usage during training
- **File Size**: NT-ViT outputs are ~464MB total (normal)
- **Training Time**: ~10-15 minutes on modern GPU

### **File Outputs Explained**
- **000-049 files**: Full dataset samples from real EEG data
- **Model .pth files**: Trained NT-ViT weights for inference
- **CortexFlow .mat files**: Ready for brain-to-image research

## ğŸ¤ **Contributing**

Feel free to contribute by:
- Adding support for more EEG datasets
- Improving the NT-ViT architecture
- Optimizing training procedures
- Enhancing documentation

### **System Requirements**
- **Python 3.11.12**: Core runtime environment
- **PyTorch 2.7.1+cu128**: Deep learning framework with CUDA 12.8 support
- **SciPy 1.15.3**: Scientific computing and MATLAB I/O
- **NumPy 2.1.3**: Numerical computing and array operations
- **Pillow**: Image processing and manipulation
- **WSL**: Windows Subsystem for Linux (recommended)

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

---

## ğŸ“– **Citation**

If you use CortexFlow EEG Adapter in your research, please cite:

```bibtex
@misc{cortexflow_eeg_adapter,
  title={CortexFlow EEG Adapter: A Novel Neural Transformer Approach for EEG-to-fMRI Synthesis},
  author={[Your Name]},
  year={2024},
  note={Dissertation Research - [Your University]},
  url={https://github.com/[your-repo]/cortexflow-eeg-adapter}
}
```

---

**ğŸš€ Ready to bridge EEG and CortexFlow? Start with `wsl python train_ntvit.py` and advance neuroscience research! ğŸ§ âœ¨**